{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 22:51:12.826765: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-29 22:51:12.826800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-29 22:51:12.827894: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-29 22:51:12.833996: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 22:51:13.503171: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('Bike-Sharing-Dataset/day.csv', index_col=0)\n",
    "\n",
    "# Drop 'dteday' if you decide it's redundant\n",
    "data.drop('dteday', axis=1, inplace=True)\n",
    "\n",
    "# Define categorical and numerical features\n",
    "'''\n",
    "season: 1,4\n",
    "yr 0,1\n",
    "mnth 1, 12\n",
    "holiday 0,1\n",
    "weekday 0,6\n",
    "workingday 0,1\n",
    "weathersit 1,3\n",
    "\n",
    "'''\n",
    "categorical_features = ['season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "numerical_features = ['temp', 'atemp', 'hum', 'windspeed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit variance is a term used in statistics and data preprocessing, particularly in the context of standardizing or scaling data. When a dataset is scaled to have unit variance, it means that the variance of each feature in the dataset is scaled to be 1.\n",
    "\n",
    "Variance measures how much the values in a dataset are spread out around the mean. When the variance is 1 (unit variance), it indicates a certain standardization of the spread of data points. \n",
    "\n",
    "In more technical terms, to achieve unit variance, each feature's values are transformed in such a way that the variance of the feature becomes 1. This is typically done by subtracting the mean of the feature from each data point and then dividing by the standard deviation of the feature. The formula for this standardization (also known as Z-score normalization) for a data point \\( x \\) is:\n",
    "\n",
    "\\[\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\mu \\) is the mean of the feature.\n",
    "- \\( \\sigma \\) is the standard deviation of the feature.\n",
    "- \\( x \\) is the original value of the data point.\n",
    "- \\( z \\) is the standardized value.\n",
    "\n",
    "This process transforms the data so that the mean of each feature is 0 and the standard deviation (and hence variance) is 1. This type of scaling is beneficial in many machine learning algorithms, especially those that are sensitive to the scale of the input data, like neural networks, by ensuring that all features contribute equally to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        #('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Separating target variable\n",
    "X = data.drop('cnt', axis=1)\n",
    "\n",
    "# also drop 'casual' and 'registered' if you want to predict 'cnt' without knowing the breakdown\n",
    "X = X.drop(['casual', 'registered'], axis=1)\n",
    "y = data['cnt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>731.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.496580</td>\n",
       "      <td>0.500684</td>\n",
       "      <td>6.519836</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>2.997264</td>\n",
       "      <td>0.683995</td>\n",
       "      <td>1.395349</td>\n",
       "      <td>0.495385</td>\n",
       "      <td>0.474354</td>\n",
       "      <td>0.627894</td>\n",
       "      <td>0.190486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.110807</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>3.451913</td>\n",
       "      <td>0.167155</td>\n",
       "      <td>2.004787</td>\n",
       "      <td>0.465233</td>\n",
       "      <td>0.544894</td>\n",
       "      <td>0.183051</td>\n",
       "      <td>0.162961</td>\n",
       "      <td>0.142429</td>\n",
       "      <td>0.077498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059130</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.337083</td>\n",
       "      <td>0.337842</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.134950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498333</td>\n",
       "      <td>0.486733</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.180975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.655417</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.730209</td>\n",
       "      <td>0.233214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.861667</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           season          yr        mnth     holiday     weekday  workingday  \\\n",
       "count  731.000000  731.000000  731.000000  731.000000  731.000000  731.000000   \n",
       "mean     2.496580    0.500684    6.519836    0.028728    2.997264    0.683995   \n",
       "std      1.110807    0.500342    3.451913    0.167155    2.004787    0.465233   \n",
       "min      1.000000    0.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "25%      2.000000    0.000000    4.000000    0.000000    1.000000    0.000000   \n",
       "50%      3.000000    1.000000    7.000000    0.000000    3.000000    1.000000   \n",
       "75%      3.000000    1.000000   10.000000    0.000000    5.000000    1.000000   \n",
       "max      4.000000    1.000000   12.000000    1.000000    6.000000    1.000000   \n",
       "\n",
       "       weathersit        temp       atemp         hum   windspeed  \n",
       "count  731.000000  731.000000  731.000000  731.000000  731.000000  \n",
       "mean     1.395349    0.495385    0.474354    0.627894    0.190486  \n",
       "std      0.544894    0.183051    0.162961    0.142429    0.077498  \n",
       "min      1.000000    0.059130    0.079070    0.000000    0.022392  \n",
       "25%      1.000000    0.337083    0.337842    0.520000    0.134950  \n",
       "50%      1.000000    0.498333    0.486733    0.626667    0.180975  \n",
       "75%      2.000000    0.655417    0.608602    0.730209    0.233214  \n",
       "max      3.000000    0.861667    0.840896    0.972500    0.507463  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the data\n",
    "#X.head()\n",
    "#y.head()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "season: 1,4\n",
    "yr 0,1\n",
    "mnth 1, 12\n",
    "holiday 0,1\n",
    "weekday 0,6\n",
    "workingday 0,1\n",
    "weathersit 1,3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season          int64\n",
      "yr              int64\n",
      "mnth            int64\n",
      "holiday         int64\n",
      "weekday         int64\n",
      "workingday      int64\n",
      "weathersit      int64\n",
      "temp          float64\n",
      "atemp         float64\n",
      "hum           float64\n",
      "windspeed     float64\n",
      "dtype: object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# check data types\n",
    "print(X.dtypes)\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the transformations\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# convert from sparse array to dense array\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n",
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# print dtypes of every array\n",
    "print(X_train.dtype)\n",
    "print(X_test.dtype)\n",
    "print(y_train.dtype)\n",
    "print(y_test.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.241438</td>\n",
       "      <td>0.258562</td>\n",
       "      <td>0.258562</td>\n",
       "      <td>0.241438</td>\n",
       "      <td>0.092466</td>\n",
       "      <td>0.080479</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.094178</td>\n",
       "      <td>0.085616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140411</td>\n",
       "      <td>0.135274</td>\n",
       "      <td>0.154110</td>\n",
       "      <td>0.130137</td>\n",
       "      <td>0.148973</td>\n",
       "      <td>0.330479</td>\n",
       "      <td>0.669521</td>\n",
       "      <td>0.628425</td>\n",
       "      <td>0.340753</td>\n",
       "      <td>0.030822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.428322</td>\n",
       "      <td>0.438220</td>\n",
       "      <td>0.438220</td>\n",
       "      <td>0.428322</td>\n",
       "      <td>0.289931</td>\n",
       "      <td>0.272267</td>\n",
       "      <td>0.252807</td>\n",
       "      <td>0.274892</td>\n",
       "      <td>0.292327</td>\n",
       "      <td>0.280037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347711</td>\n",
       "      <td>0.342309</td>\n",
       "      <td>0.361363</td>\n",
       "      <td>0.336743</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>0.470789</td>\n",
       "      <td>0.470789</td>\n",
       "      <td>0.483640</td>\n",
       "      <td>0.474369</td>\n",
       "      <td>0.172983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  584.000000  584.000000  584.000000  584.000000  584.000000  584.000000   \n",
       "mean     0.241438    0.258562    0.258562    0.241438    0.092466    0.080479   \n",
       "std      0.428322    0.438220    0.438220    0.428322    0.289931    0.272267   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    1.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9   ...          20  \\\n",
       "count  584.000000  584.000000  584.000000  584.000000  ...  584.000000   \n",
       "mean     0.068493    0.082192    0.094178    0.085616  ...    0.140411   \n",
       "std      0.252807    0.274892    0.292327    0.280037  ...    0.347711   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "               21          22          23          24          25          26  \\\n",
       "count  584.000000  584.000000  584.000000  584.000000  584.000000  584.000000   \n",
       "mean     0.135274    0.154110    0.130137    0.148973    0.330479    0.669521   \n",
       "std      0.342309    0.361363    0.336743    0.356367    0.470789    0.470789   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               27          28          29  \n",
       "count  584.000000  584.000000  584.000000  \n",
       "mean     0.628425    0.340753    0.030822  \n",
       "std      0.483640    0.474369    0.172983  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      1.000000    0.000000    0.000000  \n",
       "75%      1.000000    1.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the data using describe()\n",
    "pd.DataFrame(X_train).describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.272109</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.251701</td>\n",
       "      <td>0.251701</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>0.170068</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.258503</td>\n",
       "      <td>0.741497</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.326531</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.446567</td>\n",
       "      <td>0.418672</td>\n",
       "      <td>0.435474</td>\n",
       "      <td>0.435474</td>\n",
       "      <td>0.227624</td>\n",
       "      <td>0.252653</td>\n",
       "      <td>0.357957</td>\n",
       "      <td>0.274740</td>\n",
       "      <td>0.213687</td>\n",
       "      <td>0.252653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357957</td>\n",
       "      <td>0.376977</td>\n",
       "      <td>0.294547</td>\n",
       "      <td>0.394019</td>\n",
       "      <td>0.328924</td>\n",
       "      <td>0.439309</td>\n",
       "      <td>0.439309</td>\n",
       "      <td>0.477623</td>\n",
       "      <td>0.470547</td>\n",
       "      <td>0.141875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  147.000000  147.000000  147.000000  147.000000  147.000000  147.000000   \n",
       "mean     0.272109    0.224490    0.251701    0.251701    0.054422    0.068027   \n",
       "std      0.446567    0.418672    0.435474    0.435474    0.227624    0.252653   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    0.000000    0.500000    0.500000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9   ...          20  \\\n",
       "count  147.000000  147.000000  147.000000  147.000000  ...  147.000000   \n",
       "mean     0.149660    0.081633    0.047619    0.068027  ...    0.149660   \n",
       "std      0.357957    0.274740    0.213687    0.252653  ...    0.357957   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "               21          22          23          24          25          26  \\\n",
       "count  147.000000  147.000000  147.000000  147.000000  147.000000  147.000000   \n",
       "mean     0.170068    0.095238    0.190476    0.122449    0.258503    0.741497   \n",
       "std      0.376977    0.294547    0.394019    0.328924    0.439309    0.439309   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               27          28          29  \n",
       "count  147.000000  147.000000  147.000000  \n",
       "mean     0.653061    0.326531    0.020408  \n",
       "std      0.477623    0.470547    0.141875  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      1.000000    0.000000    0.000000  \n",
       "75%      1.000000    1.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the data using describe()\n",
    "pd.DataFrame(X_test).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out X_train and X_test to csv files\n",
    "pd.DataFrame(X_train).to_csv('X_train.csv', index=False)\n",
    "pd.DataFrame(X_test).to_csv('X_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 22:51:14.211422: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 22:51:14.241952: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a hidden layer with ReLU activation\n",
    "# The number of units/neurons in the hidden layer is a hyperparameter you can tune\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# Add the output layer with linear activation\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error message you encountered, `\"TypeError: 'SparseTensor' object is not subscriptable\"`, typically occurs when TensorFlow tries to manipulate a `SparseTensor` object in a way that is not supported. A `SparseTensor` is a TensorFlow data type used to represent sparse data (data with many zeros or missing values). In your context, this issue might be arising from how the data is being passed to the `model.fit()` function.\n",
    "\n",
    "To address this issue, let's consider a few potential causes and solutions:\n",
    "\n",
    "1. **Data Format:** Ensure that the data being fed into the model is in a format that TensorFlow can handle. Typically, data should be in the form of NumPy arrays or TensorFlow tensors. If your data is in a sparse format (like from Pandas `get_dummies` or Scikit-Learn's `OneHotEncoder`), you may need to convert it to a dense format using `.toarray()` or `.todense()`. \n",
    "\n",
    "2. **Preprocessing Steps:** Double-check the preprocessing steps. If there's a step that might be converting the data to a sparse format inadvertently, modify it to keep the data in a dense format. \n",
    "\n",
    "3. **TensorFlow Version:** Sometimes, such errors can be due to version incompatibilities. Ensure that you are using a TensorFlow version that is compatible with your code.\n",
    "\n",
    "4. **Input Check:** Before passing the data to `model.fit()`, print out the type of `X_train` and `y_train` to verify they are not `SparseTensor` objects. If they are, convert them to a dense format.\n",
    "\n",
    "5. **Model Architecture:** While not directly related to the error message, it's always good to ensure that the model architecture is appropriate for the task at hand. Since you are dealing with regression (predicting the 'cnt' variable), your current setup with a single linear layer seems appropriate.\n",
    "\n",
    "6. **GPU Usage:** To ensure TensorFlow uses the GPU, you can set up your environment to use a GPU-enabled TensorFlow version (like `tensorflow-gpu`). You can check GPU usage with `tf.config.list_physical_devices('GPU')`. Also, make sure your system's GPU drivers and CUDA are correctly installed and configured.\n",
    "\n",
    "As for the specific pip install command for Keras, you can use `pip install tensorflow` as Keras is now integrated into TensorFlow and does not require a separate installation.\n",
    "\n",
    "If the issue persists even after checking these points, there might be something specific in the data or the way it's being handled that's causing the problem. In such a case, examining the exact format and type of data being used right before `model.fit()` could provide more clues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# check types of X_train and y_train\n",
    "print(type(X_train))\n",
    "print(type(y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 795us/step - loss: 24464008.0000\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 792us/step - loss: 24453078.0000\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 801us/step - loss: 24438342.0000\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 631us/step - loss: 24417058.0000\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 632us/step - loss: 24387608.0000\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 648us/step - loss: 24350066.0000\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 953us/step - loss: 24303326.0000\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 633us/step - loss: 24247578.0000\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 584us/step - loss: 24181864.0000\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 765us/step - loss: 24106646.0000\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 796us/step - loss: 24021992.0000\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 594us/step - loss: 23927728.0000\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 605us/step - loss: 23824378.0000\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 647us/step - loss: 23710400.0000\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 958us/step - loss: 23589196.0000\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 612us/step - loss: 23458538.0000\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 599us/step - loss: 23319918.0000\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 790us/step - loss: 23172024.0000\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 668us/step - loss: 23015158.0000\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 604us/step - loss: 22850210.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7efee79da4a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 20718110.0000\n",
      "Test loss: 20718110.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 0s 793us/step - loss: 24452216.0000\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 949us/step - loss: 24442994.0000\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 909us/step - loss: 24432932.0000\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 878us/step - loss: 24421476.0000\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 871us/step - loss: 24408288.0000\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 844us/step - loss: 24393030.0000\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 709us/step - loss: 24375476.0000\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 699us/step - loss: 24355496.0000\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 815us/step - loss: 24332724.0000\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 827us/step - loss: 24306730.0000\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 22159994.0000\n",
      "Test loss: 22159994.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('Bike-Sharing-Dataset/day.csv', index_col=0)\n",
    "\n",
    "# Optionally drop 'dteday' if it's redundant\n",
    "data.drop('dteday', axis=1, inplace=True)\n",
    "\n",
    "# One-hot encode categorical variables using pd.get_dummies\n",
    "categorical_features = ['season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "data = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Separating target variable\n",
    "X = data.drop('cnt', axis=1)\n",
    "y = data['cnt']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu')) # Adding a hidden layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test_scaled, y_test)\n",
    "print('Test loss:', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
